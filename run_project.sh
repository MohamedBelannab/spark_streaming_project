#!/bin/bash

# Script de d√©marrage complet du projet Real Time Clickstream
# Usage: ./run_project.sh [start|stop|restart|status|logs]

set -e  # Arr√™ter en cas d'erreur

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fonction pour afficher les messages
info() {
    echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"
}

success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

error() {
    echo -e "${RED}‚ùå $1${NC}"
}

# Fonction pour v√©rifier les pr√©requis
check_prerequisites() {
    info "V√©rification des pr√©requis..."

    # V√©rifier Docker
    if ! command -v docker &> /dev/null; then
        error "Docker n'est pas install√©"
        exit 1
    fi
    success "Docker: $(docker --version)"

    # V√©rifier Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        error "Docker Compose n'est pas install√©"
        exit 1
    fi
    success "Docker Compose: $(docker-compose --version)"

    # V√©rifier Python
    if ! command -v python3 &> /dev/null; then
        error "Python3 n'est pas install√©"
        exit 1
    fi
    success "Python: $(python3 --version)"
}

# Fonction pour d√©marrer l'infrastructure Docker
start_docker() {
    info "D√©marrage de l'infrastructure Docker..."

    # Arr√™ter les conteneurs existants si n√©cessaire
    docker-compose down 2>/dev/null || true

    # D√©marrer tous les services
    docker-compose up -d

    success "Infrastructure Docker d√©marr√©e"

    # Attendre que les services soient pr√™ts
    info "Attente du d√©marrage des services (60 secondes)..."
    sleep 60

    # V√©rifier l'√©tat des conteneurs
    docker-compose ps
}

# Fonction pour initialiser Kafka et HDFS
init_services() {
    info "Initialisation de Kafka et HDFS..."

    # Activer l'environnement virtuel si existe
    if [ -d "venv" ]; then
        source venv/bin/activate
    else
        warning "Environnement virtuel non trouv√©. Utilisation de Python global."
    fi

    # Ex√©cuter le script d'initialisation
    python3 scripts/init_kafka.py

    success "Kafka et HDFS initialis√©s"
}

# Fonction pour d√©marrer le producer en arri√®re-plan
start_producer() {
    info "D√©marrage du Producer Kafka..."

    # Activer l'environnement virtuel si existe
    if [ -d "venv" ]; then
        source venv/bin/activate
    fi

    # D√©marrer le producer en arri√®re-plan avec auto-confirmation
    nohup python3 scripts/producer.py <<EOF > logs/producer.log 2>&1 &
n
EOF

    PRODUCER_PID=$!
    echo $PRODUCER_PID > logs/producer.pid

    success "Producer d√©marr√© (PID: $PRODUCER_PID)"
    info "Logs: tail -f logs/producer.log"
}

# Fonction pour d√©marrer Spark Streaming
start_spark() {
    info "D√©marrage de Spark Streaming..."

    # Attendre que Spark soit pr√™t
    sleep 10

    # D√©marrer Spark Streaming en arri√®re-plan
    nohup docker exec spark-master /spark/bin/spark-submit \
        --master spark://spark-master:7077 \
        --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 \
        --conf spark.executor.memory=2g \
        --conf spark.driver.memory=1g \
        /opt/spark-apps/stream_processor.py > logs/spark_streaming.log 2>&1 &

    SPARK_PID=$!
    echo $SPARK_PID > logs/spark.pid

    success "Spark Streaming d√©marr√© (PID: $SPARK_PID)"
    info "Logs: tail -f logs/spark_streaming.log"
}

# Fonction pour afficher l'√©tat du syst√®me
show_status() {
    echo ""
    info "=========================================="
    info "     √âTAT DU SYST√àME CLICKSTREAM"
    info "=========================================="
    echo ""

    # √âtat Docker
    info "üì¶ Conteneurs Docker:"
    docker-compose ps
    echo ""

    # √âtat Producer
    if [ -f "logs/producer.pid" ]; then
        PRODUCER_PID=$(cat logs/producer.pid)
        if ps -p $PRODUCER_PID > /dev/null 2>&1; then
            success "Producer: En cours (PID: $PRODUCER_PID)"
        else
            warning "Producer: Arr√™t√©"
        fi
    else
        warning "Producer: Non d√©marr√©"
    fi

    # √âtat Spark
    if [ -f "logs/spark.pid" ]; then
        SPARK_PID=$(cat logs/spark.pid)
        if ps -p $SPARK_PID > /dev/null 2>&1; then
            success "Spark Streaming: En cours (PID: $SPARK_PID)"
        else
            warning "Spark Streaming: Arr√™t√©"
        fi
    else
        warning "Spark Streaming: Non d√©marr√©"
    fi

    echo ""
    info "üåê Interfaces Web:"
    echo "  ‚Ä¢ Kafka UI:        http://localhost:8080"
    echo "  ‚Ä¢ Spark Master UI: http://localhost:8081"
    echo "  ‚Ä¢ Spark Worker UI: http://localhost:8083"
    echo "  ‚Ä¢ HDFS NameNode:   http://localhost:9870"
    echo "  ‚Ä¢ Grafana:         http://localhost:3000"
    echo "  ‚Ä¢ Airflow:         http://localhost:8085"
    echo ""
}

# Fonction pour arr√™ter tous les services
stop_services() {
    info "Arr√™t de tous les services..."

    # Arr√™ter le Producer
    if [ -f "logs/producer.pid" ]; then
        PRODUCER_PID=$(cat logs/producer.pid)
        if ps -p $PRODUCER_PID > /dev/null 2>&1; then
            kill $PRODUCER_PID 2>/dev/null || true
            success "Producer arr√™t√©"
        fi
        rm -f logs/producer.pid
    fi

    # Arr√™ter Spark
    if [ -f "logs/spark.pid" ]; then
        SPARK_PID=$(cat logs/spark.pid)
        if ps -p $SPARK_PID > /dev/null 2>&1; then
            kill $SPARK_PID 2>/dev/null || true
            success "Spark Streaming arr√™t√©"
        fi
        rm -f logs/spark.pid
    fi

    # Arr√™ter Docker
    docker-compose down
    success "Infrastructure Docker arr√™t√©e"
}

# Fonction pour afficher les logs
show_logs() {
    info "Logs disponibles:"
    echo "1. Logs Producer"
    echo "2. Logs Spark Streaming"
    echo "3. Logs Docker (tous)"
    echo "4. Logs Kafka"
    echo "5. Logs Redis"
    read -p "Choisir (1-5): " choice

    case $choice in
        1) tail -f logs/producer.log ;;
        2) tail -f logs/spark_streaming.log ;;
        3) docker-compose logs -f ;;
        4) docker-compose logs -f kafka ;;
        5) docker-compose logs -f redis ;;
        *) error "Choix invalide" ;;
    esac
}

# Fonction pour d√©marrer tout le projet
start_all() {
    echo ""
    info "=========================================="
    info "  D√âMARRAGE DU PROJET CLICKSTREAM"
    info "=========================================="
    echo ""

    # Cr√©er le dossier logs s'il n'existe pas
    mkdir -p logs

    # V√©rifier les pr√©requis
    check_prerequisites

    # D√©marrer Docker
    start_docker

    # Initialiser les services
    init_services

    # D√©marrer le Producer
    start_producer

    # Attendre un peu avant Spark
    sleep 5

    # D√©marrer Spark
    start_spark

    # Attendre que tout d√©marre
    sleep 10

    # Afficher l'√©tat
    show_status

    echo ""
    success "=========================================="
    success "  ‚úÖ PROJET D√âMARR√â AVEC SUCC√àS!"
    success "=========================================="
    echo ""

    info "Commandes utiles:"
    echo "  ‚Ä¢ Voir les logs Producer:  tail -f logs/producer.log"
    echo "  ‚Ä¢ Voir les logs Spark:     tail -f logs/spark_streaming.log"
    echo "  ‚Ä¢ Voir l'√©tat:             ./run_project.sh status"
    echo "  ‚Ä¢ Arr√™ter le projet:       ./run_project.sh stop"
    echo ""
}

# Menu principal
case "${1:-start}" in
    start)
        start_all
        ;;
    stop)
        stop_services
        ;;
    restart)
        stop_services
        sleep 5
        start_all
        ;;
    status)
        show_status
        ;;
    logs)
        show_logs
        ;;
    *)
        echo "Usage: $0 {start|stop|restart|status|logs}"
        echo ""
        echo "Commandes:"
        echo "  start   - D√©marrer tout le projet"
        echo "  stop    - Arr√™ter tous les services"
        echo "  restart - Red√©marrer le projet"
        echo "  status  - Afficher l'√©tat du syst√®me"
        echo "  logs    - Afficher les logs"
        exit 1
        ;;
esac
